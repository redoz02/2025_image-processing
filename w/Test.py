import numpy as np
import random
import pandas as pd

# ë³´ë“œ í¬ê¸° ì„¤ì •
BOARD_WIDTH = 6
BOARD_HEIGHT = 6

# ê°„ë‹¨í•œ í…ŒíŠ¸ë¦¬ìŠ¤ í™˜ê²½ ì •ì˜
class SimpleTetrisEnv:
    def __init__(self):
        self.reset()

    # í™˜ê²½ ì´ˆê¸°í™”
    def reset(self):
        self.board = np.zeros(BOARD_WIDTH, dtype=int)  # ê° ì—´ì˜ ë†’ì´ 0ìœ¼ë¡œ ì‹œì‘
        return self._get_state()

    # í˜„ì¬ ìƒíƒœ(ê° ì—´ì˜ ë†’ì´)ë¥¼ íŠœí”Œë¡œ ë°˜í™˜
    def _get_state(self):
        return tuple(self.board)

    # ì£¼ì–´ì§„ í–‰ë™(action)ì„ ìˆ˜í–‰í•˜ê³  ë‹¤ìŒ ìƒíƒœ, ë³´ìƒ, ê²Œì„ ì¢…ë£Œ ì—¬ë¶€ ë°˜í™˜
    def step(self, action):
        if self.board[action] >= BOARD_HEIGHT:
            return self._get_state(), -1, True  # í•´ë‹¹ ì—´ì´ ê°€ë“ ì°¼ìœ¼ë©´ ê²Œì„ ì˜¤ë²„
        self.board[action] += 1

        reward = 0
        # ëª¨ë“  ì—´ì˜ ë†’ì´ê°€ ê°™ìœ¼ë©´ ë³´ë“œ ì´ˆê¸°í™” (ì¤„ ì œê±° ë³´ìƒ)
        if np.all(self.board == self.board[0]):
            reward = 1
            self.board = np.zeros(BOARD_WIDTH, dtype=int)

        return self._get_state(), reward, False

# Q-learning ì„¤ì •
num_episodes = 5000  # í•™ìŠµ íšŸìˆ˜
epsilon = 0.1        # íƒí—˜ í™•ë¥ 
alpha = 0.1          # í•™ìŠµë¥ 
gamma = 0.95         # í• ì¸ìœ¨

Q = {}  # Q-í…Œì´ë¸” ì´ˆê¸°í™”

env = SimpleTetrisEnv()

# Q-learning ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
for episode in range(num_episodes):
    state = env.reset()
    done = False

    while not done:
        # ìƒíƒœê°€ ì²˜ìŒ ë“±ì¥í•˜ë©´ Qê°’ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        if state not in Q:
            Q[state] = np.zeros(BOARD_WIDTH)

        # íƒí—˜ ë˜ëŠ” ìµœì  í–‰ë™ ì„ íƒ
        if random.random() < epsilon:
            action = random.randint(0, BOARD_WIDTH - 1)
        else:
            action = np.argmax(Q[state])

        # í–‰ë™ ìˆ˜í–‰
        next_state, reward, done = env.step(action)

        # ë‹¤ìŒ ìƒíƒœ ì´ˆê¸°í™”
        if next_state not in Q:
            Q[next_state] = np.zeros(BOARD_WIDTH)

        # Qê°’ ì—…ë°ì´íŠ¸ (ë²¨ë§Œ ë°©ì •ì‹)
        Q[state][action] += alpha * (
            reward + gamma * np.max(Q[next_state]) - Q[state][action]
        )

        state = next_state

# Qê°’ì´ ë†’ì€ ìƒìœ„ ìƒíƒœ 10ê°œ ì •ë ¬
top_states = sorted(Q.items(), key=lambda x: np.max(x[1]), reverse=True)[:10]

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬
df = pd.DataFrame([(s, np.round(v, 2)) for s, v in top_states], columns=["State", "Q-Values"])

# ì½˜ì†” ì¶œë ¥
print("\nğŸ” í•™ìŠµëœ ìƒìœ„ Q-ê°’ ìƒíƒœë“¤:")
print(df)

# CSV íŒŒì¼ë¡œ ì €ì¥
df.to_csv("top_q_values.csv", index=False)
print("\nâœ… 'top_q_values.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!")
